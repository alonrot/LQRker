# @package _global_

## Reduced-Rank Student's-t process
RRTPLQRfeatures:
  hyperpars:
    nu: 2.1 # Requirement: nu > 2 [fixed]
    sigma_n:
      init: 0.5 # Initial value for standard deviation of evaluation noise
    weights_features:
      Nfeat: 200 # Number of features (i.e., number of linear models to sample)
      init: "ones" # Initial value for the elements of the diagonal of the diagonal matrix that defines the weights covariance
  dim_state: 8
  dim_control: 2
  empirical_weights:
    Q_emp: np.eye(${RRTPLQRfeatures.dim_state})
    R_emp: np.eye(${RRTPLQRfeatures.dim_control})
  initial_state_distribution:
    mu0: np.zeros((${RRTPLQRfeatures.dim_state},1))
    Sigma0: 0.1*np.eye(${RRTPLQRfeatures.dim_state})
  check_controllability: True
  learning:
    learning_rate: 0.001
    epochs: 20000
    stopping_condition:
      loss_val: -20.0

dataset:
  # Input dimensionality:
  dim: "${RRTPLQRfeatures.dim_state} + ${RRTPLQRfeatures.dim_control}"
  Nevals: 10000
  xlims: "[-2,2]" # Limits of hypercube
  noise_eval_std: 0.00
  nu: "${RRTPLQRfeatures.hyperpars.nu}"
  return_sampled_system: True
  # which_cost: "LQRCostStudent" # deprecated
  which_cost: "LQRCostChiSquared"
  with_noise: True
  massive: # Generate a number of cost functions by randomly sampling the system matrices
    use: False
    save: True
    path: "./"
    file_name: "LQRcost_dataset"
    ext: "pickle"
    Nobj_functions: 100

## Gaussian process
GaussianProcess:
  hyperpars:
    ls:
      init: 1.0
    sigma_n:
      init: 0.1
    prior_var:
      init: 1.0
    mean:
      init: 0.0
  learning:
    epochs: 20000

## Model validation
validation:
  perc_training: 20
  Ncut: 1000
  Nfuns: 100



# which_objective: "LQRCostStudent"